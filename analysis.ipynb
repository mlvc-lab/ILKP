{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('base': conda)",
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# analysis for getting evidence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pathlib\n",
    "from os.path import isfile\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import models\n",
    "from utils import *\n",
    "from data import DataLoader\n",
    "\n",
    "\n",
    "class config(object):\n",
    "    def __init__(self):\n",
    "        self.dataset = 'cifar10'\n",
    "        self.arch = 'resnet'\n",
    "        self.layers = 14\n",
    "        self.ckpt = 'ckpt_best.pth'\n",
    "        self.bn = False\n",
    "        self.width_mult = 1.0\n",
    "        self.cuda = True\n",
    "        self.types = ['max', 'min', 'avg', 'median', 'threshold']\n",
    "        self.threshold = 0.7\n",
    "        self.gpuids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|                                                 | 0/13 [00:00<?, ?layer/s]\n",
      "=> creating model 'resnet14'\n",
      "==> Loading Checkpoint 'ckpt_best.pth'\n",
      "===> Loaded Checkpoint 'ckpt_best.pth' (epoch 189)\n",
      "\n",
      "==> Get and Calculate distribution of absolute PCC\n",
      "100%|████████████████████████████████████████| 13/13 [00:04<00:00,  2.80layer/s]\n",
      "100%|████████████████████████████████████████| 13/13 [00:04<00:00,  2.79layer/s]\n",
      "100%|████████████████████████████████████████| 13/13 [00:05<00:00,  2.44layer/s]\n",
      "100%|████████████████████████████████████████| 13/13 [00:06<00:00,  1.90layer/s]\n",
      "100%|████████████████████████████████████████| 13/13 [00:06<00:00,  1.94layer/s]dict_keys(['max', 'min', 'avg', 'median', 'threshold'])\n",
      "\n",
      "===> done\n",
      "====> total time: 28.21s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    global opt, arch_name, all_dist\n",
    "    opt = config()\n",
    "\n",
    "    # set model name\n",
    "    arch_name = set_arch_name(opt)\n",
    "\n",
    "    print('\\n=> creating model \\'{}\\''.format(arch_name))\n",
    "    model = models.__dict__[opt.arch](data=opt.dataset, num_layers=opt.layers,\n",
    "                                      width_mult=opt.width_mult, batch_norm=opt.bn)\n",
    "\n",
    "    if model is None:\n",
    "        print('==> unavailable model parameters!! exit...\\n')\n",
    "        exit()\n",
    "\n",
    "    # checkpoint file\n",
    "    ckpt_dir = pathlib.Path('checkpoint')\n",
    "    dir_path = ckpt_dir / arch_name / opt.dataset\n",
    "    ckpt_file = dir_path / opt.ckpt\n",
    "\n",
    "    if isfile(ckpt_file):\n",
    "        print('==> Loading Checkpoint \\'{}\\''.format(opt.ckpt))\n",
    "        checkpoint = load_model(model, ckpt_file,\n",
    "                                main_gpu=None, use_cuda=False)\n",
    "        print('===> Loaded Checkpoint \\'{}\\' (epoch {})'.format(\n",
    "            opt.ckpt, checkpoint['epoch']))\n",
    "        print(f'\\n==> Get and Calculate distribution of absolute PCC')\n",
    "        all_dist = get_dist_abs_pcc(model)\n",
    "        print('\\n===> done')\n",
    "        return\n",
    "    else:\n",
    "        print('==> no Checkpoint found at \\'{}\\''.format(\n",
    "            opt.ckpt))\n",
    "        return\n",
    "\n",
    "\n",
    "def get_dist_abs_pcc(model):\n",
    "    w_kernel = get_kernel(model, opt)\n",
    "    num_layer = len(w_kernel)\n",
    "\n",
    "    dist_dict = {}\n",
    "    for type in opt.types:\n",
    "        dist_all = []\n",
    "        for i in tqdm(range(num_layer), ncols=80, unit='layer'):\n",
    "            ref_layer = torch.Tensor(w_kernel[i])\n",
    "            if opt.arch in hasDiffLayersArchs:\n",
    "                ref_layer = ref_layer.view(-1, 9)\n",
    "            else:\n",
    "                ref_layer = ref_layer.view(len(w_kernel[i]), -1)\n",
    "\n",
    "            ref_length = ref_layer.size()[0]\n",
    "\n",
    "            ref_mean = ref_layer.mean(dim=1, keepdim=True)\n",
    "            ref_norm = ref_layer - ref_mean\n",
    "            ref_norm_sq = (ref_norm * ref_norm).sum(dim=1)\n",
    "            ref_norm_sq_rt = torch.sqrt(ref_norm_sq)\n",
    "\n",
    "            dist = []\n",
    "            for j in range(i+1, num_layer):\n",
    "                cur_weight = torch.Tensor(w_kernel[j])\n",
    "\n",
    "                # change kernels to dw-kernel\n",
    "                if opt.arch in hasDiffLayersArchs:\n",
    "                    cur_weight = cur_weight.view(-1, 9)\n",
    "                else:\n",
    "                    cur_weight = cur_weight.view(len(w_kernel[j]), -1)\n",
    "\n",
    "                cur_length = cur_weight.size()[0]\n",
    "\n",
    "                cur_mean = cur_weight.mean(dim=1, keepdim=True)\n",
    "                cur_norm = cur_weight - cur_mean\n",
    "                cur_norm_sq_rt = torch.sqrt((cur_norm * cur_norm).sum(dim=1))\n",
    "\n",
    "                cur_dist = []\n",
    "                for k in range(cur_length):\n",
    "                    numer = torch.matmul(cur_norm[k], ref_norm.T)\n",
    "                    denom = ref_norm_sq_rt * cur_norm_sq_rt[k]\n",
    "                    pcc = numer / denom\n",
    "                    abs_pcc = torch.abs(pcc)\n",
    "                    if type == 'max':\n",
    "                        cur_dist.append(torch.max(abs_pcc).item())\n",
    "                    elif type == 'min':\n",
    "                        cur_dist.append(torch.min(abs_pcc).item())\n",
    "                    elif type == 'avg':\n",
    "                        cur_dist.append(torch.mean(abs_pcc).item())\n",
    "                    elif type == 'median':\n",
    "                        cur_dist.append(torch.median(abs_pcc).item())\n",
    "                    elif type == 'threshold':\n",
    "                        num_over_thr = torch.sum(torch.ge(abs_pcc, opt.threshold)).item()\n",
    "                        ratio_over_thr = num_over_thr / len(abs_pcc)\n",
    "                        cur_dist.append(ratio_over_thr)\n",
    "                dist.append(cur_dist)\n",
    "            dist_all.append(dist)\n",
    "        dist_dict[type] = dist_all\n",
    "    print(dist_dict.keys())\n",
    "    return dist_dict\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"====> total time: {:.2f}s\".format(elapsed_time))\n"
   ]
  },
  {
   "source": [
    "## Draw total histogram"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|                                                 | 0/13 [00:00<?, ?layer/s]Drawing total histograms...\n",
      "\n",
      "100%|████████████████████████████████████████| 13/13 [02:06<00:00,  9.70s/layer]\n",
      "Done!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "# make directory\n",
    "dir_plots = pathlib.Path('Histograms') / arch_name / opt.dataset / 'total'\n",
    "dir_plots.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Drawing total histograms...\\n')\n",
    "for i in tqdm(range(len(all_dist['max'])), ncols=80, unit='layer'):\n",
    "    for j in range(len(all_dist['max'][i])):\n",
    "        cur_num = i + j + 1\n",
    "        num_pcc = len(all_dist['max'][i][j])\n",
    "\n",
    "        plt.style.use('seaborn-deep')\n",
    "        fig, ax = plt.subplots(figsize=(8,6), dpi=150)\n",
    "\n",
    "        list_ymax = []\n",
    "        for type in all_dist.keys():\n",
    "            if type == 'threshold':\n",
    "                continue\n",
    "            cur_dist = all_dist[type][i][j]\n",
    "            y_vals, x_vals, e_ = ax.hist(cur_dist, label=type, alpha=0.75, bins=min(num_pcc, 256))\n",
    "            ymax = round((max(y_vals) / num_pcc) + 0.02, 2)\n",
    "            list_ymax.append(ymax)\n",
    "        y_max = max(list_ymax)\n",
    "        ax.set_yticks(ticks=np.arange(0.0, y_max * num_pcc, 0.01 * num_pcc))\n",
    "        ax.set_ylim(ax.get_yticks()[0], ax.get_yticks()[-1])\n",
    "        ax.set_xlim(-0.01, 1.01)\n",
    "        ax.yaxis.set_major_formatter(PercentFormatter(xmax=num_pcc))\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.savefig(dir_plots / 'abs_pcc_ref{:02d}_cur{:02d}.png'.format(i, cur_num),\n",
    "                    bbox_inches='tight', dpi=150)\n",
    "        plt.clf()\n",
    "\n",
    "print('\\nDone!!!')\n"
   ]
  },
  {
   "source": [
    "## Draw all histogram"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|                                                 | 0/13 [00:00<?, ?layer/s]Drawing all histograms (type: max)...\n",
      "\n",
      "100%|████████████████████████████████████████| 13/13 [00:52<00:00,  4.06s/layer]\n",
      "  0%|                                                 | 0/13 [00:00<?, ?layer/s]Drawing all histograms (type: min)...\n",
      "\n",
      "100%|████████████████████████████████████████| 13/13 [00:49<00:00,  3.83s/layer]\n",
      "  0%|                                                 | 0/13 [00:00<?, ?layer/s]Drawing all histograms (type: avg)...\n",
      "\n",
      "100%|████████████████████████████████████████| 13/13 [00:57<00:00,  4.42s/layer]\n",
      "  0%|                                                 | 0/13 [00:00<?, ?layer/s]Drawing all histograms (type: median)...\n",
      "\n",
      "100%|████████████████████████████████████████| 13/13 [00:50<00:00,  3.86s/layer]\n",
      "  0%|                                                 | 0/13 [00:00<?, ?layer/s]Drawing all histograms (type: threshold0.4)...\n",
      "\n",
      "100%|████████████████████████████████████████| 13/13 [00:51<00:00,  3.98s/layer]\n",
      "Done!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "for type in all_dist.keys():\n",
    "    # make directory\n",
    "    type_name = type\n",
    "    if type == 'threshold':\n",
    "        type_name += str(opt.threshold)\n",
    "    dir_plots = pathlib.Path('Histograms') / arch_name / opt.dataset / type_name\n",
    "    dir_plots.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f'Drawing all histograms (type: {type_name})...\\n')\n",
    "    for i in tqdm(range(len(all_dist[type])), ncols=80, unit='layer'):\n",
    "        for j in range(len(all_dist[type][i])):\n",
    "            cur_dist = all_dist[type][i][j]\n",
    "            num_pcc = len(cur_dist)\n",
    "            min_pcc = min(cur_dist)\n",
    "            max_pcc = max(cur_dist)\n",
    "            med_pcc = np.median(cur_dist)\n",
    "            avg_pcc = np.mean(cur_dist)\n",
    "            var_pcc = np.var(cur_dist)\n",
    "            std_pcc = np.std(cur_dist)\n",
    "            textstr = '\\n'.join((\n",
    "                r'$\\min=%.6f$' % (min_pcc, ),\n",
    "                r'$\\max=%.6f$' % (max_pcc, ),\n",
    "                r'$\\mathrm{median}=%.6f$' % (med_pcc, ),\n",
    "                r'$\\mu=%.6f$' % (avg_pcc, ),\n",
    "                r'$\\sigma^{2}=%.6f$' % (var_pcc, ),\n",
    "                r'$\\sigma=%.6f$' % (std_pcc, )))\n",
    "\n",
    "            plt.style.use('seaborn-deep')\n",
    "            fig, ax = plt.subplots(figsize=(8,6), dpi=150)\n",
    "            cur_num = i + j + 1\n",
    "            y_vals, x_vals, e_ = ax.hist(cur_dist, bins=min(num_pcc, 256))\n",
    "            y_max = round((max(y_vals) / num_pcc) + 0.02, 2)\n",
    "            ax.set_yticks(ticks=np.arange(0.0, y_max * num_pcc, 0.01 * num_pcc))\n",
    "            ax.set_ylim(ax.get_yticks()[0], ax.get_yticks()[-1])\n",
    "            ax.set_xlim(-0.01, 1.01)\n",
    "            ax.yaxis.set_major_formatter(PercentFormatter(xmax=num_pcc))\n",
    "            # these are matplotlib.patch.Patch properties\n",
    "            props = dict(boxstyle='round', facecolor='lightsteelblue', alpha=0.5)\n",
    "            # place a text box in upper left in axes coords\n",
    "            ax.text(0.03, 0.96, textstr, transform=ax.transAxes, fontsize=9,\n",
    "                    verticalalignment='top', bbox=props)\n",
    "            plt.savefig(dir_plots / 'abs_pcc_ref{:02d}_cur{:02d}.png'.format(i, cur_num),\n",
    "                        bbox_inches='tight', dpi=150)\n",
    "            plt.clf()\n",
    "\n",
    "print('\\nDone!!!')"
   ]
  },
  {
   "source": [
    "## Draw total merge histogram"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drawing total histograms...\n",
      "\n",
      "100%|████████████████████████████████████████| 13/13 [00:47<00:00,  3.63s/layer]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "# make directory\n",
    "dir_plots = pathlib.Path('Histograms') / arch_name / opt.dataset / 'merged'\n",
    "dir_plots.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Drawing total histograms...\\n')\n",
    "plt.style.use('seaborn-deep')\n",
    "fig, axs = plt.subplots(nrows=opt.layers-1, ncols=opt.layers-1, figsize=(80,60), dpi=150)\n",
    "for i in tqdm(range(len(all_dist['max'])), ncols=80, unit='layer'):\n",
    "    for j in range(len(all_dist['max'][i])):\n",
    "        cur_num = i + j + 1\n",
    "        num_pcc = len(all_dist['max'][i][j])\n",
    "\n",
    "        list_ymax = []\n",
    "        for type in all_dist.keys():\n",
    "            if type == 'threshold':\n",
    "                continue\n",
    "            cur_dist = all_dist[type][i][j]\n",
    "            y_vals, x_vals, e_ = axs[i,cur_num].hist(cur_dist, label=type,\n",
    "                alpha=0.75, bins=min(num_pcc, 256))\n",
    "            ymax = round((max(y_vals) / num_pcc) + 0.02, 2)\n",
    "            list_ymax.append(ymax)\n",
    "        y_max = max(list_ymax)\n",
    "        axs[i,cur_num].set_yticks(ticks=np.arange(0.0, y_max * num_pcc, 0.01 * num_pcc))\n",
    "        axs[i,cur_num].set_ylim(axs[i,cur_num].get_yticks()[0], axs[i,cur_num].get_yticks()[-1])\n",
    "        axs[i,cur_num].set_xlim(-0.01, 1.01)\n",
    "        axs[i,cur_num].yaxis.set_major_formatter(PercentFormatter(xmax=num_pcc))\n",
    "        if i == 0 and j == len(all_dist['max'][i]) - 1:\n",
    "            axs[i,cur_num].legend(loc='center', bbox_to_anchor=(1.2, 0), ncol=1, fontsize=15)\n",
    "        # plt.legend(loc='upper right')\n",
    "# plt.tight_layout()\n",
    "plt.savefig(dir_plots / 'total.png', bbox_inches='tight', dpi=150)\n",
    "# plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "source": [
    "## Draw histograms of weights each layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|                                                 | 0/13 [00:00<?, ?layer/s]\n",
      "=> creating model 'resnet14'\n",
      "==> Loading Checkpoint 'ckpt_best.pth'\n",
      "===> Loaded Checkpoint 'ckpt_best.pth' (epoch 189)\n",
      "Drawing convolution weights histogram...\n",
      "\n",
      "100%|████████████████████████████████████████| 13/13 [00:09<00:00,  1.42layer/s]====> total time: 9.16s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pathlib\n",
    "from os.path import isfile\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import models\n",
    "from utils import *\n",
    "from data import DataLoader\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "class config(object):\n",
    "    def __init__(self):\n",
    "        self.dataset = 'cifar10'\n",
    "        self.arch = 'resnet'\n",
    "        self.layers = 14\n",
    "        self.ckpt = 'ckpt_best.pth'\n",
    "        self.bn = False\n",
    "        self.width_mult = 1.0\n",
    "        self.cuda = True\n",
    "        self.types = ['max', 'min', 'avg', 'median', 'threshold']\n",
    "        self.threshold = 0.4\n",
    "        self.gpuids = [0]\n",
    "\n",
    "\n",
    "def main():\n",
    "    opt = config()\n",
    "\n",
    "    # set model name\n",
    "    arch_name = set_arch_name(opt)\n",
    "\n",
    "    print('\\n=> creating model \\'{}\\''.format(arch_name))\n",
    "    model = models.__dict__[opt.arch](data=opt.dataset, num_layers=opt.layers,\n",
    "                                      width_mult=opt.width_mult, batch_norm=opt.bn)\n",
    "\n",
    "    if model is None:\n",
    "        print('==> unavailable model parameters!! exit...\\n')\n",
    "        exit()\n",
    "\n",
    "    # checkpoint file\n",
    "    ckpt_dir = pathlib.Path('checkpoint')\n",
    "    dir_path = ckpt_dir / arch_name / opt.dataset\n",
    "    ckpt_file = dir_path / opt.ckpt\n",
    "\n",
    "    if isfile(ckpt_file):\n",
    "        print('==> Loading Checkpoint \\'{}\\''.format(opt.ckpt))\n",
    "        checkpoint = load_model(model, ckpt_file,\n",
    "                                main_gpu=None, use_cuda=False)\n",
    "        print('===> Loaded Checkpoint \\'{}\\' (epoch {})'.format(\n",
    "            opt.ckpt, checkpoint['epoch']))\n",
    "    else:\n",
    "        print('==> no Checkpoint found at \\'{}\\''.format(\n",
    "            opt.ckpt))\n",
    "        return\n",
    "\n",
    "    # make directory\n",
    "    dir_plots = pathlib.Path('Histograms') / arch_name / opt.dataset / 'conv_weights'\n",
    "    dir_plots.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    w_kernel = get_kernel(model, opt)\n",
    "    num_layer = len(w_kernel)\n",
    "\n",
    "    print('Drawing convolution weights histogram...\\n')\n",
    "    for i in tqdm(range(num_layer), ncols=80, unit='layer'):\n",
    "        cur_w = np.reshape(w_kernel[i], (-1)).tolist()\n",
    "        num_w = len(cur_w)\n",
    "        min_w = min(cur_w)\n",
    "        max_w = max(cur_w)\n",
    "        med_w = np.median(cur_w)\n",
    "        avg_w = np.mean(cur_w)\n",
    "        var_w = np.var(cur_w)\n",
    "        std_w = np.std(cur_w)\n",
    "        textstr = '\\n'.join((\n",
    "            r'$\\mathrm{\\# weights}=%d$' % (num_w, ),\n",
    "            r'$\\min=%.6f$' % (min_w, ),\n",
    "            r'$\\max=%.6f$' % (max_w, ),\n",
    "            r'$\\mathrm{median}=%.6f$' % (med_w, ),\n",
    "            r'$\\mu=%.6f$' % (avg_w, ),\n",
    "            r'$\\sigma^{2}=%.6f$' % (var_w, ),\n",
    "            r'$\\sigma=%.6f$' % (std_w, )))\n",
    "\n",
    "        plt.style.use('seaborn-deep')\n",
    "        fig, ax = plt.subplots(figsize=(8,6), dpi=150)\n",
    "        y_vals, x_vals, e_ = ax.hist(cur_w, alpha=0.75, bins=min(num_w, 256))\n",
    "        y_max = round((max(y_vals) / num_w) + 0.02, 2)\n",
    "        ax.set_yticks(ticks=np.arange(0.0, y_max * num_w, 0.01 * num_w))\n",
    "        ax.set_ylim(ax.get_yticks()[0], ax.get_yticks()[-1])\n",
    "        ax.yaxis.set_major_formatter(PercentFormatter(xmax=num_w))\n",
    "        # these are matplotlib.patch.Patch properties\n",
    "        props = dict(boxstyle='round', facecolor='lightsteelblue', alpha=0.5)\n",
    "        # place a text box in upper left in axes coords\n",
    "        ax.text(0.03, 0.96, textstr, transform=ax.transAxes, fontsize=9,\n",
    "                verticalalignment='top', bbox=props)\n",
    "        plt.savefig(dir_plots / 'Weights_in_Layer{0:02d}.png'.format(i),\n",
    "                    bbox_inches='tight', dpi=150)\n",
    "        plt.clf()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"====> total time: {:.2f}s\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "source": [
    "## zip histogram folder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8e9145f5e570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mplots_zip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Histograms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplots_zip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m     def writestr(self, zinfo_or_arcname, data,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "plots_zip = zipfile.ZipFile('Histograms.zip', 'w')\n",
    " \n",
    "for folder, subfolders, files in os.walk('Histograms'):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            plots_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder, file), 'Histograms'), compress_type = zipfile.ZIP_DEFLATED)\n",
    "\n",
    "plots_zip.close()"
   ]
  },
  {
   "source": [
    "## torch profiler test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n=> creating model 'resnet14'\n==> Loading Checkpoint 'ckpt_best.pth'\n===> Loaded Checkpoint 'ckpt_best.pth' (epoch 189)\n--------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \nName                        Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    CPU Mem          Self CPU Mem     CUDA Mem         Self CUDA Mem    Number of Calls  \n--------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \nempty                       6.73%            660.294us        6.73%            660.294us        5.412us          1.19%            433.409us        3.553us          0 b              0 b              337.24 Mb        337.24 Mb        122              \nbatch_norm                  1.12%            110.248us        37.81%           3.707ms          247.149us        10.86%           3.961ms          264.053us        0 b              0 b              141.01 Mb        0 b              15               \n_batch_norm_impl_index      3.90%            382.729us        36.68%           3.597ms          239.799us        10.69%           3.900ms          260.028us        0 b              0 b              141.01 Mb        0 b              15               \ncudnn_batch_norm            24.87%           2.439ms          30.65%           3.005ms          200.337us        9.57%            3.490ms          232.653us        0 b              0 b              141.01 Mb        0 b              15               \nempty_like                  0.88%            86.724us         1.90%            186.238us        12.416us         0.34%            124.929us        8.329us          0 b              0 b              141.00 Mb        0 b              15               \nconv2d                      1.00%            97.848us         42.61%           4.178ms          278.515us        14.41%           5.256ms          350.432us        0 b              0 b              140.00 Mb        0 b              15               \nconvolution                 1.04%            102.310us        41.61%           4.080ms          271.992us        14.24%           5.196ms          346.377us        0 b              0 b              140.00 Mb        0 b              15               \n_convolution                4.58%            448.866us        40.57%           3.978ms          265.171us        14.06%           5.130ms          341.969us        0 b              0 b              140.00 Mb        0 b              15               \ncudnn_convolution           24.41%           2.393ms          33.35%           3.270ms          217.994us        12.69%           4.630ms          308.691us        0 b              0 b              140.00 Mb        -56.15 Mb        15               \nadaptive_avg_pool2d         0.28%            27.292us         1.38%            135.294us        135.294us        0.29%            106.496us        106.496us        0 b              0 b              64.00 Kb         0 b              1                \nmean                        0.47%            46.321us         0.57%            56.184us         56.184us         0.14%            52.225us         52.225us         0 b              0 b              64.00 Kb         0 b              1                \nresize_                     0.84%            82.585us         0.84%            82.585us         2.664us          0.17%            63.202us         2.039us          0 b              0 b              10.00 Kb         10.00 Kb         31               \naddmm                       1.26%            124.013us        1.68%            164.586us        164.586us        0.29%            105.473us        105.473us        0 b              0 b              10.00 Kb         0 b              1                \nadd                         3.40%            333.778us        4.38%            429.530us        28.635us         0.58%            209.918us        13.995us         0 b              0 b              7.50 Kb          0 b              15               \nScatter                     0.50%            49.092us         1.18%            116.032us        116.032us        0.32%            115.936us        115.936us        0 b              0 b              0 b              0 b              1                \nchunk                       0.13%            12.851us         0.65%            63.498us         63.498us         0.17%            63.168us         63.168us         0 b              0 b              0 b              0 b              1                \nsize                        7.52%            737.481us        7.52%            737.481us        2.269us          1.76%            642.136us        1.976us          0 b              0 b              0 b              0 b              325              \nsplit                       0.18%            17.900us         0.48%            47.283us         47.283us         0.13%            47.648us         47.648us         0 b              0 b              0 b              0 b              1                \nnarrow                      0.11%            10.792us         0.27%            26.601us         26.601us         0.07%            26.528us         26.528us         0 b              0 b              0 b              0 b              1                \nslice                       0.09%            8.758us          0.14%            13.529us         13.529us         0.04%            13.472us         13.472us         0 b              0 b              0 b              0 b              1                \nas_strided                  0.14%            13.486us         0.14%            13.486us         3.372us          0.03%            10.078us         2.520us          0 b              0 b              0 b              0 b              4                \nto                          0.04%            3.442us          0.04%            3.442us          3.442us          0.01%            3.296us          3.296us          0 b              0 b              0 b              0 b              1                \ncontiguous                  2.91%            285.138us        2.91%            285.138us        2.357us          0.66%            242.463us        2.004us          0 b              0 b              0 b              0 b              121              \nstride                      1.48%            145.112us        1.48%            145.112us        2.303us          0.34%            125.348us        1.990us          0 b              0 b              0 b              0 b              63               \nis_complex                  0.44%            42.684us         0.44%            42.684us         2.846us          0.08%            28.671us         1.911us          0 b              0 b              0 b              0 b              15               \nview                        1.36%            133.020us        1.36%            133.020us        7.390us          0.21%            77.826us         4.324us          0 b              0 b              0 b              0 b              18               \nrelu_                       5.98%            586.799us        7.61%            746.437us        57.418us         2.93%            1.069ms          82.235us         0 b              0 b              0 b              0 b              13               \nthreshold_                  1.63%            159.638us        1.63%            159.638us        12.280us         1.96%            714.755us        54.981us         0 b              0 b              0 b              0 b              13               \nadd_                        2.19%            215.185us        2.19%            215.185us        35.864us         1.54%            560.128us        93.355us         0 b              0 b              0 b              0 b              6                \nflatten                     0.10%            10.197us         0.43%            42.042us         42.042us         0.08%            29.696us         29.696us         0 b              0 b              0 b              0 b              1                \nreshape                     0.07%            6.650us          0.30%            29.779us         29.779us         0.06%            21.503us         21.503us         0 b              0 b              0 b              0 b              1                \nt                           0.20%            20.056us         0.29%            28.476us         28.476us         0.05%            17.408us         17.408us         0 b              0 b              0 b              0 b              1                \ntranspose                   0.05%            5.389us          0.09%            8.420us          8.420us          0.02%            6.145us          6.145us          0 b              0 b              0 b              0 b              1                \nexpand                      0.06%            6.131us          0.09%            8.373us          8.373us          0.02%            6.144us          6.144us          0 b              0 b              0 b              0 b              1                \n--------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \nSelf CPU time total: 9.805ms\nCUDA time total: 36.480ms\n\n====> total time: 0.16s\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "def main():\n",
    "    global opt, arch_name, all_dist\n",
    "    opt = config()\n",
    "\n",
    "    # set model name\n",
    "    arch_name = set_arch_name(opt)\n",
    "\n",
    "    print('\\n=> creating model \\'{}\\''.format(arch_name))\n",
    "    model = models.__dict__[opt.arch](data=opt.dataset, num_layers=opt.layers,\n",
    "                                      width_mult=opt.width_mult, batch_norm=opt.bn)\n",
    "\n",
    "    if model is None:\n",
    "        print('==> unavailable model parameters!! exit...\\n')\n",
    "        exit()\n",
    "\n",
    "    if opt.cuda:\n",
    "        torch.cuda.set_device(opt.gpuids[0])\n",
    "        with torch.cuda.device(opt.gpuids[0]):\n",
    "            model = model.cuda()\n",
    "        model = nn.DataParallel(model, device_ids=opt.gpuids,\n",
    "                                output_device=opt.gpuids[0])\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    # checkpoint file\n",
    "    ckpt_dir = pathlib.Path('checkpoint')\n",
    "    dir_path = ckpt_dir / arch_name / opt.dataset\n",
    "    ckpt_file = dir_path / opt.ckpt\n",
    "\n",
    "    if isfile(ckpt_file):\n",
    "        print('==> Loading Checkpoint \\'{}\\''.format(opt.ckpt))\n",
    "        checkpoint = load_model(model, ckpt_file,\n",
    "                                main_gpu=opt.gpuids[0], use_cuda=opt.cuda)\n",
    "        print('===> Loaded Checkpoint \\'{}\\' (epoch {})'.format(\n",
    "            opt.ckpt, checkpoint['epoch']))\n",
    "        inputs = torch.randn(256, 3, 32, 32).cuda()\n",
    "        with profiler.profile(use_cuda=True, profile_memory=True, record_shapes=True) as prof:\n",
    "            model(inputs)\n",
    "        print(prof.key_averages().table(sort_by=\"cuda_memory_usage\"))\n",
    "        prof.export_chrome_trace(\"trace.json\")\n",
    "        return\n",
    "    else:\n",
    "        print('==> no Checkpoint found at \\'{}\\''.format(\n",
    "            opt.ckpt))\n",
    "        return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"====> total time: {:.2f}s\".format(elapsed_time))\n"
   ]
  },
  {
   "source": [
    "## heatmap of number of most similar kernel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pathlib\n",
    "from os.path import isfile\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import models\n",
    "from utils import *\n",
    "from data import DataLoader\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "class config(object):\n",
    "    def __init__(self):\n",
    "        self.dataset = 'cifar10'\n",
    "        self.arch = 'resnet'\n",
    "        self.layers = 14\n",
    "        self.ckpt = 'ckpt_best.pth'\n",
    "        self.bn = False\n",
    "        self.width_mult = 1.0\n",
    "        self.cuda = True\n",
    "        self.threshold = 0.4\n",
    "        self.gpuids = [0]\n",
    "\n",
    "\n",
    "def main():\n",
    "    global opt, arch_name, all_dist\n",
    "    opt = config()\n",
    "\n",
    "    # set model name\n",
    "    arch_name = set_arch_name(opt)\n",
    "\n",
    "    print('\\n=> creating model \\'{}\\''.format(arch_name))\n",
    "    model = models.__dict__[opt.arch](data=opt.dataset, num_layers=opt.layers,\n",
    "                                      width_mult=opt.width_mult, batch_norm=opt.bn)\n",
    "\n",
    "    if model is None:\n",
    "        print('==> unavailable model parameters!! exit...\\n')\n",
    "        exit()\n",
    "\n",
    "    # checkpoint file\n",
    "    ckpt_dir = pathlib.Path('checkpoint')\n",
    "    dir_path = ckpt_dir / arch_name / opt.dataset\n",
    "    ckpt_file = dir_path / opt.ckpt\n",
    "\n",
    "    if isfile(ckpt_file):\n",
    "        print('==> Loading Checkpoint \\'{}\\'..'.format(opt.ckpt))\n",
    "        checkpoint = load_model(model, ckpt_file,\n",
    "                                main_gpu=None, use_cuda=False)\n",
    "        print('===> Loaded Checkpoint \\'{}\\' (epoch {})'.format(\n",
    "            opt.ckpt, checkpoint['epoch']))\n",
    "        print(f'\\n==> Get and Calculate distribution of absolute PCC..')\n",
    "        all_dist = get_dist_abs_pcc(model)\n",
    "        print('\\n===> done')\n",
    "        print('\\n==> Draw histogram..')\n",
    "        histograms(all_dist)\n",
    "        return\n",
    "    else:\n",
    "        print('==> no Checkpoint found at \\'{}\\''.format(\n",
    "            opt.ckpt))\n",
    "        return\n",
    "\n",
    "\n",
    "def get_dist_abs_pcc(model):\n",
    "    w_kernel = get_kernel(model, opt)\n",
    "    num_layer = len(w_kernel)\n",
    "\n",
    "    dist_all = []\n",
    "    for i in tqdm(range(num_layer), ncols=80, unit='layer'):\n",
    "        ref_layer = torch.Tensor(w_kernel[i])\n",
    "        if opt.arch in hasDiffLayersArchs:\n",
    "            ref_layer = ref_layer.view(-1, 9)\n",
    "        else:\n",
    "            ref_layer = ref_layer.view(len(w_kernel[i]), -1)\n",
    "\n",
    "        ref_length = ref_layer.size()[0]\n",
    "\n",
    "        ref_mean = ref_layer.mean(dim=1, keepdim=True)\n",
    "        ref_norm = ref_layer - ref_mean\n",
    "        ref_norm_sq_rt = torch.sqrt((ref_norm * ref_norm).sum(dim=1))\n",
    "\n",
    "        dist = []\n",
    "        for j in range(i+1, num_layer):\n",
    "            cur_weight = torch.Tensor(w_kernel[j])\n",
    "\n",
    "            # change kernels to dw-kernel\n",
    "            if opt.arch in hasDiffLayersArchs:\n",
    "                cur_weight = cur_weight.view(-1, 9)\n",
    "            else:\n",
    "                cur_weight = cur_weight.view(len(w_kernel[j]), -1)\n",
    "\n",
    "            cur_length = cur_weight.size()[0]\n",
    "\n",
    "            cur_mean = cur_weight.mean(dim=1, keepdim=True)\n",
    "            cur_norm = cur_weight - cur_mean\n",
    "            cur_norm_sq_rt = torch.sqrt((cur_norm * cur_norm).sum(dim=1))\n",
    "\n",
    "            cur_dist = []\n",
    "            for k in range(cur_length):\n",
    "                numer = torch.matmul(cur_norm[k], ref_norm.T)\n",
    "                denom = ref_norm_sq_rt * cur_norm_sq_rt[k]\n",
    "                pcc = numer / denom\n",
    "                abs_pcc = torch.abs(pcc)\n",
    "                cur_dist.append(torch.max(abs_pcc).item())\n",
    "            dist.append(cur_dist)\n",
    "        dist_all.append(dist)\n",
    "    return dist_all\n",
    "\n",
    "\n",
    "def histograms(all_dist):\n",
    "    # make directory\n",
    "    dir_plots = pathlib.Path('Histograms') / arch_name / opt.dataset / 'heatmap_N_maxpcc'\n",
    "    dir_plots.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # calculate\n",
    "    histogram_dist = []\n",
    "    heatmap_dist = []\n",
    "    for j in range(len(all_dist[0])):\n",
    "        cur_num = j+1\n",
    "        max_nums = []\n",
    "        max_layer_nums = []\n",
    "        for k in range(len(all_dist[0][j])):\n",
    "            cur_max = 0.0\n",
    "            max_ref_layer_num = 0\n",
    "            for i in range(cur_num):\n",
    "                if cur_max < all_dist[i][j-i][k]:\n",
    "                    cur_max = all_dist[i][j-i][k]\n",
    "                    max_ref_layer_num = i\n",
    "            max_nums.append(cur_max)\n",
    "            max_layer_nums.append(max_ref_layer_num)\n",
    "        histogram_dist.append(max_nums)\n",
    "        heatmap_dist.append(max_layer_nums)\n",
    "\n",
    "    # draw heatmap\n",
    "    print('===> Draw heatmap...')\n",
    "    plt.clf()\n",
    "    num_layer = len(all_dist)\n",
    "    heatmap_cnt = np.zeros((num_layer,num_layer))\n",
    "    for i in range(1, num_layer):\n",
    "        for j in range(len(heatmap_dist[i-1])):\n",
    "            similar_layer_num = heatmap_dist[i-1][j]\n",
    "            heatmap_cnt[i][similar_layer_num] += 100\n",
    "        heatmap_cnt[i] = heatmap_cnt[i] / len(heatmap_dist[i-1])\n",
    "    heatmap_cnt = heatmap_cnt.transpose()\n",
    "    fig = plt.pcolor(heatmap_cnt, cmap='hot')\n",
    "    plt.xticks(np.arange(0.5, num_layer, 1), [\"{}\".format(x) for x in range(num_layer)])\n",
    "    plt.yticks(np.arange(0.5, num_layer, 1), [\"{}\".format(x) for x in range(num_layer)])\n",
    "    plt.xlabel('Source layer', fontsize=12)\n",
    "    plt.ylabel('Target layer', fontsize=12)\n",
    "    plt.colorbar()\n",
    "    plt.savefig(dir_plots / 'heatmap.png', figsize=(8,6), dpi=150, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    print('====> done')\n",
    "\n",
    "    # draw histograms\n",
    "    print('===> Draw histograms...')\n",
    "    for i in tqdm(range(len(histogram_dist)), ncols=80, unit='layer'):\n",
    "        cur_pcc = histogram_dist[i]\n",
    "        num_pcc = len(cur_pcc)\n",
    "        min_pcc = min(cur_pcc)\n",
    "        max_pcc = max(cur_pcc)\n",
    "        med_pcc = np.median(cur_pcc)\n",
    "        avg_pcc = np.mean(cur_pcc)\n",
    "        var_pcc = np.var(cur_pcc)\n",
    "        std_pcc = np.std(cur_pcc)\n",
    "        textstr = '\\n'.join((\n",
    "            r'$\\mathrm{\\# weights}=%d$' % (num_pcc, ),\n",
    "            r'$\\min=%.6f$' % (min_pcc, ),\n",
    "            r'$\\max=%.6f$' % (max_pcc, ),\n",
    "            r'$\\mathrm{median}=%.6f$' % (med_pcc, ),\n",
    "            r'$\\mu=%.6f$' % (avg_pcc, ),\n",
    "            r'$\\sigma^{2}=%.6f$' % (var_pcc, ),\n",
    "            r'$\\sigma=%.6f$' % (std_pcc, )))\n",
    "\n",
    "        plt.style.use('seaborn-deep')\n",
    "        fig, ax = plt.subplots(figsize=(8,6), dpi=150)\n",
    "        y_vals, x_vals, e_ = ax.hist(cur_pcc, alpha=0.75, bins=min(num_pcc, 256))\n",
    "        y_max = round((max(y_vals) / num_pcc) + 0.02, 2)\n",
    "        ax.set_yticks(ticks=np.arange(0.0, y_max * num_pcc, 0.01 * num_pcc))\n",
    "        ax.set_ylim(ax.get_yticks()[0], ax.get_yticks()[-1])\n",
    "        ax.set_xlim(-0.01, 1.01)\n",
    "        ax.yaxis.set_major_formatter(PercentFormatter(xmax=num_pcc))\n",
    "        # these are matplotlib.patch.Patch properties\n",
    "        props = dict(boxstyle='round', facecolor='lightsteelblue', alpha=0.5)\n",
    "        # place a text box in upper left in axes coords\n",
    "        ax.text(0.03, 0.96, textstr, transform=ax.transAxes, fontsize=9,\n",
    "                verticalalignment='top', bbox=props)\n",
    "        plt.savefig(dir_plots / 'Max_PCCs_in_cur{:02d}.png'.format(i+1),\n",
    "                    bbox_inches='tight', dpi=150)\n",
    "        plt.clf()\n",
    "    print('====> done')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"====> total time: {:.2f}s\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}